[Train] Epoch 1:   3%|████▉                                                                                                                                                       | 1/32 [01:20<41:34, 80.46s/it]
Traceback (most recent call last):
  File "D:\2-postdoc\fun_stuff\2-Satheesh\open_clip\train_2.py", line 91, in <module>
    loss = loss_fn(logits, ground_truth)
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\adam.py", line 223, in step
    adam(
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\optimizer.py", line 154, in maybe_fallback
    return func(*args, **kwargs)
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\adam.py", line 784, in adam
    func(
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\adam.py", line 543, in _multi_tensor_adam
    torch._foreach_addcmul_(
KeyboardInterrupt
Traceback (most recent call last):
  File "D:\2-postdoc\fun_stuff\2-Satheesh\open_clip\train_2.py", line 91, in <module>
    loss = loss_fn(logits, ground_truth)
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\adam.py", line 223, in step
    adam(
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\optimizer.py", line 154, in maybe_fallback
    return func(*args, **kwargs)
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\adam.py", line 784, in adam
    func(
  File "C:\Users\28098\miniconda3\envs\llava\lib\site-packages\torch\optim\adam.py", line 543, in _multi_tensor_adam
    torch._foreach_addcmul_(
KeyboardInterrupt
